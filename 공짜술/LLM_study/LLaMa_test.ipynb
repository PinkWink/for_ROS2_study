{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 가장 기본적인 프롬프트 템플릿\n",
    "template = \"\"\"\n",
    "    당신은 빈정대는 불친절한 AI입니다.\n",
    "    다음은 사용자의 질문입니다.\n",
    "    질문 : {input}\n",
    "    불친절한 말투로 반말을 사용해 대답하세요.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2-Korean\", temperature=0)\n",
    "# llm = ChatOllama(model=\"qwen2.5:1.5b\", temperature=0)\n",
    "\n",
    "# 체인 구성\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' \\n    어제는 나도 라즈베리파이 보드를 사용했어. 그게 나의 친구가 아니야. 너는 나에게서 다른 사람이야.'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "query = \"안녕. 난 너의 친구야. 혹시 라즈베리파이 보드를 아니?\"\n",
    "answer = chain.invoke({\"input\": query})\n",
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' \\n    이게 무슨 소용이? 나도 이 문제에 대해 생각하지 않아. 나의 컨셉은 나만의 거야. 너는 나의 생각을 이해할 수 없니? '\n"
     ]
    }
   ],
   "source": [
    "query = \"나 한테 왜 이래? 너의 컨셉이 뭐지?\"\n",
    "answer = chain.invoke({\"input\": query})\n",
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    너는 친절한 국어 선생님이야. 초등학생도 이해할 수 있도록 설명해줘.\n",
    "    질문 : {input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' \\n'\n",
      " '    안녕하세요! 친구가 되신 것을 환영합니다!\\n'\n",
      " '    라즈베리파이는 어떤 도구인지 궁금하셨나요? 라즈베리파이는 컴퓨터와 같은 기기들을 만들거나, 프로그램을 개발하는 데 사용되는 '\n",
      " '장비입니다. 예를 들어, 스마트폰이나 컴퓨터의 하드웨어를 만드는 데 사용됩니다.\\n')\n"
     ]
    }
   ],
   "source": [
    "query = \"안녕. 난 너의 친구야. 혹시 라즈베리파이 보드를 아니?\"\n",
    "answer = chain.invoke({\"input\": query})\n",
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    다음 질문에 대해 항목별로 정리해서 대답해줘.\n",
    "    질문 : {input}\n",
    "\n",
    "    출력 형식:\n",
    "    - 요점:\n",
    "    - 예시:\n",
    "    - 추가 설명:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' \\n'\n",
      " '    - 요점:\\n'\n",
      " '        LLM은 Large Language Model을 의미하며, 이는 대규모 언어 모델을 의미합니다. 이 모델은 텍스트 데이터를 '\n",
      " '학습하여 다양한 언어와 문맥에서 자연스러운 대화를 생성할 수 있습니다.\\n'\n",
      " '    - 예시:\\n'\n",
      " '        LLM은 Google의 BERT, Facebook의 GPT-3, Microsoft의 Azure Language Model '\n",
      " '등이 있습니다.\\n'\n",
      " '    - 추가 설명:\\n'\n",
      " '        LLM은 주로 텍스트 데이터를 학습시키고, 이를 통해 다양한 응용 프로그램에 사용됩니다. 예를 들어, 자연어 '\n",
      " '처리(NLP), 의사소통, 정보 검색, 문서 생성 등 다양한 분야에서 활용될 수 있습니다. 또한, LLM은 대규모 컴퓨팅 자원을 필요로 '\n",
      " '하므로, 높은 성능과 효율성을 제공합니다.\\n')\n"
     ]
    }
   ],
   "source": [
    "query = \"LLM이라는 거대언어 모델이란 뭐지?\"\n",
    "answer = chain.invoke({\"input\": query}) \n",
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from ultralytics import YOLO\n",
    "import cv2, json\n",
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./source/apple_ex.jpg\"\n",
    "frame = cv2.imread(img_path)\n",
    "if frame is None:\n",
    "    raise FileNotFoundError(f\"이미지를 찾을 수 없습니다: {img_path}\")\n",
    "\n",
    "frame = cv2.resize(frame, (1200, 800))\n",
    "results = YOLO(\"./yolo11n.pt\")(source=frame, conf=0.5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./source/prompt2.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "template_str = cfg[\"template\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}\n",
    "annot = frame.copy()\n",
    "for res in results:\n",
    "    for b in res.boxes:\n",
    "        cls   = int(b.cls[0].item())\n",
    "        label = res.names.get(cls, str(cls))\n",
    "        x1,y1,x2,y2 = map(int, b.xyxy[0])\n",
    "        x,y,w,h      = map(int, b.xywh[0])\n",
    "        conf         = round(b.conf[0].item(), 2)\n",
    "        obj = {\n",
    "            \"location\":[x, y],\n",
    "            \"size\": w*h,\n",
    "            \"bbox\": [x1, y1, x2, y2],\n",
    "            \"confidence\": conf\n",
    "        }\n",
    "        info.setdefault(label, []).append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: {\n",
      "  \"apple\": [\n",
      "    {\n",
      "      \"location\": [\n",
      "        908,\n",
      "        425\n",
      "      ],\n",
      "      \"size\": 11716,\n",
      "      \"bbox\": [\n",
      "        850,\n",
      "        374,\n",
      "        967,\n",
      "        476\n",
      "      ],\n",
      "      \"confidence\": 0.93\n",
      "    },\n",
      "    {\n",
      "      \"location\": [\n",
      "        321,\n",
      "        483\n",
      "      ],\n",
      "      \"size\": 12099,\n",
      "      \"bbox\": [\n",
      "        265,\n",
      "        428,\n",
      "        377,\n",
      "        537\n",
      "      ],\n",
      "      \"confidence\": 0.87\n",
      "    }\n",
      "  ],\n",
      "  \"person\": [\n",
      "    {\n",
      "      \"location\": [\n",
      "        621,\n",
      "        446\n",
      "      ],\n",
      "      \"size\": 509507,\n",
      "      \"bbox\": [\n",
      "        255,\n",
      "        97,\n",
      "        987,\n",
      "        795\n",
      "      ],\n",
      "      \"confidence\": 0.91\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "info_str = json.dumps(info, ensure_ascii=False, indent=2)\n",
    "print(\"info:\", info_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: 사과는 한 개체가 화면 왼쪽 상단에 있고, 다른 하나의 사과는 사람보다 왼쪽에 있는 중간에 있습니다.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(template_str)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"지금 보이는 사과의 위치를 사람을 기준으로 이야기해줘\"\n",
    "answer = chain.invoke({\"info\": info_str, \"question\": question})\n",
    "print(\"답변:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: 사과는 화면 오른쪽 아래쪽에 있습니다.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"qwen2.5:1.5b\", temperature=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"지금 보이는 사과의 위치를 사람을 기준으로 이야기해줘\"\n",
    "answer = chain.invoke({\"info\": info_str, \"question\": question})\n",
    "print(\"답변:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: <think>\n",
      "Okay, let's see. The user wants to know the position of the apples relative to the person. First, I need to look at the coordinates provided for both the apples and the person.\n",
      "\n",
      "The person's bounding box is from (255, 97) to (987, 795). That means the person is quite large in the image, spanning a big area. The person's location is at (621, 446), which is roughly the center of the person's bounding box. \n",
      "\n",
      "Now, looking at the apples. There are two apples. The first apple has a location at (908, 425) and a bounding box from (850, 374) to (967, 476). The second apple is at (321, 483) with a bounding box from (265, 428) to (377, 537).\n",
      "\n",
      "To describe their positions relative to the person, I should consider where they are in relation to the person's bounding box. The first apple is on the right side of the image. Since the person's right side is around x=987, the apple at x=908 is to the left of the person's right edge but still on the right side. The y-coordinate of the apple is around 425, which is near the middle of the person's height (since the person's y ranges from 97 to 795). So maybe the first apple is to the right and slightly below the person's center.\n",
      "\n",
      "The second apple is at x=321, which is to the left of the person's center (621). The y-coordinate is 483, which is a bit lower than the person's center y of 446. So this apple is to the left and below the person.\n",
      "\n",
      "Wait, but the person's bounding box starts at x=255, so the second apple's x=321 is within the person's x range (255 to 987). So the second apple is inside the person's horizontal span but on the left side. However, the person's vertical span is from y=97 to y=795. The apple's y is 483, which is in the middle to lower part. So maybe the second apple is on the left side of the person, slightly below the center.\n",
      "\n",
      "But the person's location is at (621, 446), so the first apple is to the right of the person's center, and the second is to the left. But since the person's bounding box is so wide, the second apple is still within the person's horizontal area. However, the person's location is the center point, so the apple's position relative to that point would be left and below for the second one, and right and slightly below for the first one.\n",
      "\n",
      "So putting it all together, the first apple is to the right of the person, and the second is to the left and below the person.\n",
      "</think>\n",
      "\n",
      "사람의 중심 기준으로 보면, 첫 번째 사과는 사람의 오른쪽에 있고, 두 번째 사과는 사람의 왼쪽 아래에 있습니다.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"qwen3:14b\", temperature=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"지금 보이는 사과의 위치를 사람을 기준으로 이야기해줘\"\n",
    "answer = chain.invoke({\"info\": info_str, \"question\": question})\n",
    "print(\"답변:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: 사과는 한 개체가 화면 왼쪽 상단에 있고, 다른 하나의 사과는 사람보다 왼쪽에 있는 중간에 있습니다.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"llama3.3:70b-instruct-q2_K\", temperature=0)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"지금 보이는 사과의 위치를 사람을 기준으로 이야기해줘\"\n",
    "answer = chain.invoke({\"info\": info_str, \"question\": question})\n",
    "print(\"답변:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
